{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UKB9Wz5twR6"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "from elasticsearch import Elasticsearch\n",
        "\n",
        "es = Elasticsearch('http://localhost:9200')\n",
        "client_info = es.info()\n",
        "print('Connected to Elasticsearch!')\n",
        "pprint(client_info.body)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating an index with data\n",
        "import json\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "es.indices.delete(index='my_index', ignore_unavailable=True)\n",
        "es.indices.create(index='my_index')\n",
        "\n",
        "operations = []\n",
        "clothes_documents = json.load(open(\"../data/astronomy.json\"))\n",
        "\n",
        "for document in clothes_documents:\n",
        "    operations.append({'index': {'_index': 'my_index'}})\n",
        "    operations.append(document)\n",
        "\n",
        "response = es.bulk(operations=operations)\n",
        "pprint(response.body)"
      ],
      "metadata": {
        "id": "FVN-O4ZGt0wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#count the number of documents in the index\n",
        "count = es.count(index='my_index')\n",
        "print('Number of documents in index:', count.body['count'])"
      ],
      "metadata": {
        "id": "HpH6ryY4t_kX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sql query\n",
        "query = {\n",
        "    \"query\": \"SELECT title FROM my_index ORDER BY id LIMIT 5\" #returns titles to all documents\n",
        "}\n",
        "\n",
        "response = es.sql.query(body=query)\n",
        "for row in response['rows']:\n",
        "    print(row)"
      ],
      "metadata": {
        "id": "lwpjhg8ruF1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#changing the format of the response\n",
        "query = {\n",
        "    \"query\": \"SELECT * FROM my_index\",\n",
        "}\n",
        "\n",
        "response = es.sql.query(body=query, format='json') #to json (txt, csv, tsv)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "KWkfWTSDuWI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filtering\n",
        "query = {\n",
        "    \"query\": \"SELECT * FROM my_index\"\n",
        "}\n",
        "\n",
        "response = es.sql.query(\n",
        "    body=query,\n",
        "    filter={\n",
        "        \"term\": {\n",
        "            \"title.keyword\": \"Black Holes\" #where title is black holes\n",
        "        }\n",
        "    },\n",
        ")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "BDSsdHtRukkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pagination\n",
        "query = {\n",
        "    \"query\": \"SELECT * FROM my_index ORDER BY id DESC\"\n",
        "}\n",
        "\n",
        "response = es.sql.query(\n",
        "    body=query,\n",
        "    format='json',\n",
        "    fetch_size=5,\n",
        ")\n",
        "response.body"
      ],
      "metadata": {
        "id": "1H3Mnnpju3sI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#translating the query\n",
        "translate_query = {\n",
        "    \"query\": \"SELECT * FROM my_index WHERE content LIKE '%universe%' ORDER BY id DESC LIMIT 20\"\n",
        "}\n",
        "\n",
        "translated_query = es.sql.translate(body=translate_query)\n",
        "translated_query.body"
      ],
      "metadata": {
        "id": "nYUm2CJ1vArO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ILM Policy #readmore\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "policy = {\n",
        "    \"phases\": {\n",
        "        \"hot\": {\n",
        "            \"actions\": {\n",
        "                \"rollover\": {\n",
        "                    \"max_age\": \"5m\", #the index is rolled over after 5 minutes\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \"delete\": {\n",
        "            \"min_age\": \"20m\", #at 20 minutes the index is deleted\n",
        "            \"actions\": {\n",
        "                \"delete\": {}\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "response = es.ilm.put_lifecycle(name=\"cpu_usage_policy_v2\", policy=policy)\n",
        "pprint(response.body)\n"
      ],
      "metadata": {
        "id": "2kAaTckhu6pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyzers\n",
        "\n",
        "#HTML filter removes unwanted html tags\n",
        "from pprint import pprint\n",
        "\n",
        "response = es.indices.analyze(\n",
        "    char_filter=[\n",
        "        \"html_strip\"\n",
        "    ],\n",
        "    text=\"I&apos;m so happy</b>!</p>\",\n",
        ")\n",
        "pprint(response.body)"
      ],
      "metadata": {
        "id": "K6ZsS_t_b65t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mapping maps characters e.g. arabic to the roman\n",
        "response = es.indices.analyze(\n",
        "    tokenizer=\"keyword\",\n",
        "    char_filter=[\n",
        "        {\n",
        "            \"type\": \"mapping\",\n",
        "            \"mappings\": [\n",
        "                \"٠ => 0\",\n",
        "                \"١ => 1\",\n",
        "                \"٢ => 2\",\n",
        "                \"٣ => 3\",\n",
        "                \"٤ => 4\",\n",
        "                \"٥ => 5\",\n",
        "                \"٦ => 6\",\n",
        "                \"٧ => 7\",\n",
        "                \"٨ => 8\",\n",
        "                \"٩ => 9\"\n",
        "            ]\n",
        "        }\n",
        "    ],\n",
        "    text=\"I saw comet Tsuchinshan Atlas in ٢٠٢٤\",\n",
        ")\n",
        "pprint(response.body)"
      ],
      "metadata": {
        "id": "Qy0VbykOcHLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizers splits tokens into individual words\n",
        "response = es.indices.analyze(\n",
        "    tokenizer=\"standard\",\n",
        "    text=\"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\",\n",
        ")\n",
        "tokens = response.body[\"tokens\"]\n",
        "for token in tokens:\n",
        "    print(f\"Token: '{token['token']}', Type: {token['type']}\")"
      ],
      "metadata": {
        "id": "kreZABYYcYff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converts to lower case\n",
        "response = es.indices.analyze(\n",
        "    tokenizer=\"lowercase\",\n",
        "    text=\"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\",\n",
        ")\n",
        "tokens = response.body[\"tokens\"]\n",
        "for token in tokens:\n",
        "    print(f\"Token: '{token['token']}', Type: {token['type']}\")"
      ],
      "metadata": {
        "id": "7JAImOg5cgO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#white space removes white space\n",
        "response = es.indices.analyze(\n",
        "    tokenizer=\"whitespace\",\n",
        "    text=\"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\",\n",
        ")\n",
        "tokens = response.body[\"tokens\"]\n",
        "for token in tokens:\n",
        "    print(f\"Token: '{token['token']}', Type: {token['type']}\")"
      ],
      "metadata": {
        "id": "0eAmEloWcpg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing everything after the apostrophee\n",
        "response = es.indices.analyze(\n",
        "    tokenizer=\"standard\",\n",
        "    filter=[\n",
        "        \"apostrophe\"\n",
        "    ],\n",
        "    text=\"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\",\n",
        ")\n",
        "tokens = response.body[\"tokens\"]\n",
        "for token in tokens:\n",
        "    print(f\"Token: '{token['token']}'\")"
      ],
      "metadata": {
        "id": "ZoKgq6vcdAE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converts symbols to value\n",
        "response = es.indices.analyze(\n",
        "    tokenizer=\"standard\",\n",
        "    filter=[\n",
        "        \"decimal_digit\"\n",
        "    ],\n",
        "    text=\"I saw comet Tsuchinshan Atlas in ٢٠٢٤\",\n",
        ")\n",
        "tokens = response.body[\"tokens\"]\n",
        "for token in tokens:\n",
        "    print(f\"Token: '{token['token']}'\")"
      ],
      "metadata": {
        "id": "TpolG3XsdFTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reverses the text\n",
        "response = es.indices.analyze(\n",
        "    tokenizer=\"standard\",\n",
        "    filter=[\n",
        "        \"reverse\"\n",
        "    ],\n",
        "    text=\"I saw comet Tsuchinshan Atlas in ٢٠٢٤\",\n",
        ")\n",
        "tokens = response.body[\"tokens\"]\n",
        "for token in tokens:\n",
        "    print(f\"Token: '{token['token']}'\")"
      ],
      "metadata": {
        "id": "tdxFeTcBdSma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#standard analyzer\n",
        "response = es.indices.analyze(\n",
        "    analyzer=\"standard\",\n",
        "    text=\"I saw comet Tsuchinshan Atlas in ٢٠٢٤\",\n",
        ")\n",
        "tokens = response.body[\"tokens\"]\n",
        "for token in tokens:\n",
        "    print(f\"Token: '{token['token']}'\")"
      ],
      "metadata": {
        "id": "TH0JsDTbdU_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stop removes stop words\n",
        "response = es.indices.analyze(\n",
        "    analyzer=\"stop\",\n",
        "    text=\"I saw comet Tsuchinshan Atlas in ٢٠٢٤\",\n",
        ")\n",
        "tokens = response.body[\"tokens\"]\n",
        "for token in tokens:\n",
        "    print(f\"Token: '{token['token']}'\")"
      ],
      "metadata": {
        "id": "jxzQbSAiddmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#keyword analyzer returns the sentence as a token\n",
        "response = es.indices.analyze(\n",
        "    analyzer=\"keyword\",\n",
        "    text=\"I saw comet Tsuchinshan Atlas in ٢٠٢٤\",\n",
        ")\n",
        "tokens = response.body[\"tokens\"]\n",
        "for token in tokens:\n",
        "    print(f\"Token: '{token['token']}'\")"
      ],
      "metadata": {
        "id": "5HYbIR3zdico"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#working with synonyms\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "settings = {\n",
        "    \"settings\": {\n",
        "        \"analysis\": {\n",
        "            \"filter\": {\n",
        "                \"synonym_filter\": {\n",
        "                    \"type\": \"synonym\",\n",
        "                    \"synonyms\": [ #created\n",
        "                        \"car, automobile, vehicle\",\n",
        "                        \"tv, television\",\n",
        "                        \"smartphone, mobile, cell phone\",\n",
        "                        \"jupyter, jupyter notebook, jupyterlab\",\n",
        "                        \"jupiter, mars, earth, venus, mercury, saturn, uranus, neptune => planet\"\n",
        "                    ]\n",
        "                }\n",
        "            },\n",
        "            \"analyzer\": {\n",
        "                \"synonym_analyzer\": {\n",
        "                    \"tokenizer\": \"standard\",\n",
        "                    \"filter\": [\n",
        "                        \"lowercase\",\n",
        "                        \"synonym_filter\" #added to the analyzer\n",
        "                    ]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"description\": {\n",
        "                \"type\": \"text\",\n",
        "                \"analyzer\": \"synonym_analyzer\" #added in the mapping\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "index_name = \"my_synonym_index\"\n",
        "es.indices.delete(index=index_name, ignore_unavailable=True)\n",
        "response = es.indices.create(index=index_name, body=settings)\n",
        "pprint(response.body)"
      ],
      "metadata": {
        "id": "uJL9C3KadrhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add docunebts to the index and then search with the synonyms\n",
        "query = {\n",
        "    \"query\": {\n",
        "        \"match\": {\n",
        "            \"description\": \"vehicle\"\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "response = es.search(index=index_name, body=query)\n",
        "\n",
        "print(\"Search Results:\")\n",
        "for hit in response[\"hits\"][\"hits\"]:\n",
        "    print(hit[\"_source\"])"
      ],
      "metadata": {
        "id": "mxm-7S76gF88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using synonyms only at search time\n",
        "settings = {\n",
        "    \"settings\": {\n",
        "        \"analysis\": {\n",
        "            \"filter\": {\n",
        "                \"synonym_filter\": {\n",
        "                    \"type\": \"synonym\",\n",
        "                    \"synonyms\": [\n",
        "                        \"car, automobile, vehicle\",\n",
        "                        \"tv, television\"\n",
        "                    ]\n",
        "                }\n",
        "            },\n",
        "            \"analyzer\": {\n",
        "                \"index_analyzer\": {\n",
        "                    \"tokenizer\": \"standard\",\n",
        "                    \"filter\": [\"lowercase\"] #remove synonym filter and add it to the search analyzer below\n",
        "                },\n",
        "                \"search_analyzer\": {\n",
        "                    \"tokenizer\": \"standard\",\n",
        "                    \"filter\": [\"lowercase\", \"synonym_filter\"]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"description\": {\n",
        "                \"type\": \"text\",\n",
        "                \"analyzer\": \"index_analyzer\",\n",
        "                \"search_analyzer\": \"search_analyzer\" #add search analyzer that has the synonym filter\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "es.indices.delete(index=index_name)\n",
        "response = es.indices.create(index=index_name, body=settings)\n",
        "pprint(response.body)"
      ],
      "metadata": {
        "id": "karupAaNg04U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Options"
      ],
      "metadata": {
        "id": "hqL1HuVNkyQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#make output human redable\n",
        "response = es.cluster.stats(human=True) #human = true\n",
        "pprint(response[\"nodes\"][\"jvm\"])\n"
      ],
      "metadata": {
        "id": "OPu_1_Zzkzjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fetching results from the time of running the query\n",
        "response = es.search(\n",
        "    index=index_name,\n",
        "    body={\n",
        "        \"query\": {\n",
        "            \"range\": {\n",
        "                \"created_on\": {\n",
        "                    \"gte\": \"2024-09-22||+1d/d\",  # 2024-09-23\n",
        "                    \"lte\": \"now/d\"  # 2024-11-16\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        ")\n",
        "hits = response['hits']['hits']\n",
        "print(f\"Found {len(hits)} documents\")\n"
      ],
      "metadata": {
        "id": "kG4AXyHvk5S7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VajKdbcNncsd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}