{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  langchain langchain-community langchain-groq langgraph"
      ],
      "metadata": {
        "id": "t4y6bvBtkqTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MV9dNDD3kagb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from typing import TypedDict\n",
        "from google.colab import userdata\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LLM set up\n",
        "groq_api_key=userdata.get('GROQ_API')\n",
        "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"Gemma2-9b-It\")\n",
        "llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ0Q1NKNkl8X",
        "outputId": "1880020d-1363-4cb9-c039-c11a04546f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x797eda5c4490>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x797ed9977c50>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SEARCH SET UP\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')\n",
        "#tool = TavilySearchResults(max_results=3) #increased number of results\n",
        "##print(type(tool))\n",
        "#print(tool.name)"
      ],
      "metadata": {
        "id": "OIUNZPFXlafS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatState(TypedDict):\n",
        "    messages: list\n",
        "    query: str\n",
        "\n",
        "@tool\n",
        "def query_fact_check_websites(query: str):\n",
        "    \"\"\"\n",
        "    Return a list of articles published on pesacheck.org and africacheck.org\n",
        "    related to a user's question. If no articles are found, return a message\n",
        "    indicating that.\n",
        "    \"\"\"\n",
        "    print(f\"Searching for articles related to: {query} on pesacheck.org and africacheck.org\")\n",
        "\n",
        "    search_tool = TavilySearchResults(max_results=5) # Increased max_results for potentially more results\n",
        "\n",
        "    # Search Pesacheck\n",
        "    pesacheck_results = search_tool.invoke(f\"{query} site:pesacheck.org\")\n",
        "    pesacheck_articles = [{\"source\": \"Pesacheck.org\", \"title\": res['title'], \"url\": res['url'], \"content\": res['content']} for res in pesacheck_results]\n",
        "\n",
        "    # Search Africacheck\n",
        "    africacheck_results = search_tool.invoke(f\"{query} site:africacheck.org\")\n",
        "    africacheck_articles = [{\"source\": \"Africacheck.org\", \"title\": res['title'], \"url\": res['url'], \"content\": res['content']} for res in africacheck_results]\n",
        "\n",
        "    all_articles = pesacheck_articles + africacheck_articles\n",
        "\n",
        "    if not all_articles:\n",
        "        return \"No articles found on pesacheck.org or africacheck.org related to your query.\"\n",
        "    else:\n",
        "        # Format the results nicely\n",
        "        formatted_results = \"Found the following articles:\\n\\n\"\n",
        "        for article in all_articles:\n",
        "            formatted_results += f\"Source: {article['source']}\\n\"\n",
        "            formatted_results += f\"Title: {article['title']}\\n\"\n",
        "            formatted_results += f\"URL: {article['url']}\\n\"\n",
        "            formatted_results += f\"Content Snippet: {article['content'][:200]}...\\n\\n\" # Provide a content snippet\n",
        "\n",
        "        return formatted_results\n"
      ],
      "metadata": {
        "id": "gYfMvx_zmMIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the graph\n",
        "workflow = StateGraph(ChatState)\n",
        "\n",
        "#Add nodes\n",
        "# Add an LLM node to process the user input and potentially generate tool calls\n",
        "workflow.add_node(\"llm\", lambda state: llm.invoke(state[\"messages\"]))\n",
        "workflow.add_node(\"search\", ToolNode([query_fact_check_websites]))\n",
        "\n",
        "# Define the entry point\n",
        "workflow.set_entry_point(\"llm\")\n",
        "\n",
        "# Define the exit point\n",
        "# The LLM can either call the search tool or finish\n",
        "workflow.add_edge(\"llm\", \"search\") # Directly go to search after LLM for this simple example\n",
        "\n",
        "# Define the exit point for the search tool\n",
        "workflow.add_edge(\"search\", END)\n",
        "\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "PJ63Ld09q0To"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = app.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Find articles on pesacheck.org and africacheck.org about Coffee is Uganda's biggest export.\"}]})\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "oGsuaSFRrtG1",
        "outputId": "a5de5bb5-f265-4251-d800-973cc46e70ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No AIMessage found in input",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/prebuilt/tool_node.py\u001b[0m in \u001b[0;36m_parse_input\u001b[0;34m(self, input, store)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m             latest_ai_message = next(\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0mm\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAIMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-e9765701cf4c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Find articles on pesacheck.org and africacheck.org about Coffee is Uganda's biggest export.\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2717\u001b[0m         \u001b[0minterrupts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInterrupt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2719\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   2720\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2721\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2434\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2435\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2436\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2437\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2438\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/prebuilt/tool_node.py\u001b[0m in \u001b[0;36m_func\u001b[0;34m(self, input, config, store)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mstore\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseStore\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     ) -> Any:\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mtool_calls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0mconfig_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0minput_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput_type\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/prebuilt/tool_node.py\u001b[0m in \u001b[0;36m_parse_input\u001b[0;34m(self, input, store)\u001b[0m\n\u001b[1;32m    446\u001b[0m             )\n\u001b[1;32m    447\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No AIMessage found in input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         tool_calls = [\n",
            "\u001b[0;31mValueError\u001b[0m: No AIMessage found in input"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add necessary imports if not already present\n",
        "import os\n",
        "import json\n",
        "from typing import TypedDict, Annotated # Import Annotated here\n",
        "from google.colab import userdata\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.messages import AIMessage # Import AIMessage\n",
        "from langchain_core.messages import HumanMessage # Import HumanMessage\n",
        "import operator # Import the operator module\n",
        "\n",
        "\n",
        "# Ensure necessary libraries are installed\n",
        "!pip install --upgrade --quiet  langchain langchain-community langchain-groq langgraph beautifulsoup4 requests\n",
        "\n",
        "# LLM set up\n",
        "groq_api_key = userdata.get('GROQ_API')\n",
        "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"Gemma2-9b-It\")\n",
        "\n",
        "# SEARCH SET UP\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')\n",
        "\n",
        "class ChatState(TypedDict):\n",
        "    # Use Annotated and operator.add to manage messages\n",
        "    messages: Annotated[list, operator.add]\n",
        "    # Keep query for potential future use, but it's not strictly needed for the current tool signature\n",
        "    query: str\n",
        "\n",
        "\n",
        "@tool\n",
        "def query_fact_check_websites(query: str):\n",
        "    \"\"\"\n",
        "    Return a list of articles published on pesacheck.org and africacheck.org\n",
        "    related to a user's question. If no articles are found, return a message\n",
        "    indicating that.\n",
        "    \"\"\"\n",
        "    print(f\"Searching for articles related to: {query} on pesacheck.org and africacheck.org\")\n",
        "\n",
        "    search_tool = TavilySearchResults(max_results=5)\n",
        "\n",
        "    # Search Pesacheck\n",
        "    pesacheck_results = search_tool.invoke(f\"{query} site:pesacheck.org\")\n",
        "    pesacheck_articles = [{\"source\": \"Pesacheck.org\", \"title\": res['title'], \"url\": res['url'], \"content\": res['content']} for res in pesacheck_results]\n",
        "\n",
        "    # Search Africacheck\n",
        "    africacheck_results = search_tool.invoke(f\"{query} site:africacheck.org\")\n",
        "    africacheck_articles = [{\"source\": \"Africacheck.org\", \"title\": res['title'], \"url\": res['url'], \"content\": res['content']} for res in africacheck_results]\n",
        "\n",
        "    all_articles = pesacheck_articles + africacheck_articles\n",
        "\n",
        "    if not all_articles:\n",
        "        return \"No articles found on pesacheck.org or africacheck.org related to your query.\"\n",
        "    else:\n",
        "        formatted_results = \"Found the following articles:\\n\\n\"\n",
        "        for article in all_articles:\n",
        "            formatted_results += f\"Source: {article['source']}\\n\"\n",
        "            formatted_results += f\"Title: {article['title']}\\n\"\n",
        "            formatted_results += f\"URL: {article['url']}\\n\"\n",
        "            formatted_results += f\"Content Snippet: {article['content'][:200]}...\\n\\n\"\n",
        "\n",
        "        return formatted_results\n",
        "\n",
        "# Define the graph\n",
        "workflow = StateGraph(ChatState)\n",
        "\n",
        "# Add nodes\n",
        "# Add an LLM node. We need to bind the tool to the LLM so it knows how to call it.\n",
        "# The LLM's output will be added to the state's messages.\n",
        "workflow.add_node(\"llm\", lambda state: llm.bind_tools([query_fact_check_websites]).invoke(state[\"messages\"]))\n",
        "# The ToolNode will execute the tool called by the LLM.\n",
        "workflow.add_node(\"search\", ToolNode([query_fact_check_websites]))\n",
        "\n",
        "# Define the entry point\n",
        "workflow.set_entry_point(\"llm\")\n",
        "\n",
        "# Define the conditional edge from the LLM node\n",
        "# The LLM can either call a tool or finish\n",
        "def should_continue(state):\n",
        "    messages = state['messages']\n",
        "    last_message = messages[-1]\n",
        "    # If the last message is an AIMessage with tool_calls, then we should go to the search node\n",
        "    if isinstance(last_message, AIMessage) and hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
        "        return \"search\"\n",
        "    else:\n",
        "        # Otherwise, the LLM has finished, so we should end\n",
        "        return END\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"llm\", # Start node\n",
        "    should_continue, # Conditional logic\n",
        "    {\n",
        "        \"search\": \"search\", # If should_continue returns \"search\", go to the search node\n",
        "        END: END # If should_continue returns END, end the graph\n",
        "    }\n",
        ")\n",
        "\n",
        "# Define the edge from the search node back to the LLM\n",
        "# After the search tool executes, its results are added to the state, and the LLM should process them.\n",
        "workflow.add_edge(\"search\", \"llm\")\n",
        "\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()\n",
        "\n",
        "# Example usage:\n",
        "results = app.invoke({\"messages\": [HumanMessage(content=\"Find articles on pesacheck.org and africacheck.org about Coffee is Uganda's biggest export.\")]})\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcrXP-BltJhm",
        "outputId": "5aa80d8c-1782-49a8-cc7a-aedcb87bf739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'messages': [HumanMessage(content=\"Find articles on pesacheck.org and africacheck.org about Coffee is Uganda's biggest export.\", additional_kwargs={}, response_metadata={})]}\n"
          ]
        }
      ]
    }
  ]
}